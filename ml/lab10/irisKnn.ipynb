{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randrange\n",
    "import math\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('irisData.csv', 'rb') as csv_file:\n",
    "    iris_data_reader = csv.reader(csv_file, delimiter=',', quotechar='|')\n",
    "    for row in iris_data_reader:\n",
    "        if row[4] == 'Iris-setosa':\n",
    "            data.append([float(1), float(row[0]), float(row[1]), float(row[2]), float(row[3]), 1])\n",
    "        elif row[4] == 'Iris-versicolor':\n",
    "            data.append([float(1), float(row[0]), float(row[1]), float(row[2]), float(row[3]), 2])\n",
    "        else:\n",
    "            data.append([float(1), float(row[0]), float(row[1]), float(row[2]), float(row[3]), 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_dataset(data):\n",
    "#     minmax = list()\n",
    "#     for i in range(len(data[0])):\n",
    "#         col_values = [row[i] for row in data]\n",
    "#         value_min = min(col_values)\n",
    "#         value_max = max(col_values)\n",
    "#         minmax.append([value_min, value_max])\n",
    "# \n",
    "#     for row in data:\n",
    "#         for i in range(len(row) - 1):\n",
    "#             if minmax[i][1] != minmax[i][0]:\n",
    "#                 row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "# \n",
    "# \n",
    "# normalize_dataset(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "    \"\"\" Split data set for n folds. Need for k-fold validation\"\"\"\n",
    "    dataset_split = []\n",
    "    dataset_copy = copy.copy(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = []\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(elem1, elem2):\n",
    "    distance = 0\n",
    "    for index in range(len(elem1)-1):\n",
    "        distance += pow((elem1[index] - elem2[index]), 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nnn(train_data, test_data, k):\n",
    "    score = 0\n",
    "    for test_elem in test_data:\n",
    "        distances = []\n",
    "        for train_elem in train_data:\n",
    "            distance = euclidean_distance(train_elem, test_elem)\n",
    "            distances.append((distance, train_elem[-1]))\n",
    "        sorted_by_distance = sorted(distances, key=lambda tup: tup[0])\n",
    "\n",
    "        cnt = Counter()\n",
    "        for distance in sorted_by_distance[0:k]:\n",
    "            cnt[distance[1]] += 1\n",
    "\n",
    "        if test_elem[-1] == cnt.most_common(1)[0][0]:\n",
    "            score += 1\n",
    "    return score / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986666666667\n12\n"
     ]
    }
   ],
   "source": [
    "best_score = None\n",
    "best_k = 0\n",
    "for k in xrange(1, 30):\n",
    "    folds = cross_validation_split(data, 5)\n",
    "    scores = []\n",
    "    for test_set in folds:\n",
    "        train_set = [item for item in data if item not in test_set]\n",
    "        score = k_nnn(train_set, test_set, k)\n",
    "    \n",
    "        scores.append(score)\n",
    "\n",
    "    if sum(scores)/len(scores) > best_score:\n",
    "        best_score = sum(scores)/len(scores)\n",
    "        best_k = k\n",
    "\n",
    "print best_score\n",
    "print best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В алгоритме кросс валидации у меня сделано так, что выборка разбивается на фолды каждый раз рандомно (для разных k в k-nn), поэтому при различных запусках кросс валидации получается разный результат точности.  Но в целом лучшая точность получется при k > 7 (точность около 98%).\n",
    "\n",
    "Если выполнять предварительную нормализацию данных, то результат точности получается хуже (примерно на 2%). Вот это я не знаю почему..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проклятие размерности — проблема, связанная с экспоненциальным возрастанием количества данных из-за увеличения размерности пространства. Напимер, как было показано на лекции по k-nn. Т.е. чем больше размерность, тем гораздо больше размер обучающей выборки нам нужен.\n",
    "В многомерных пространствах расстояние между объекта не так как мы привыкли, c ростом числа признаков необходимый объем обучающей выборки растет экспоненциально, и это становится серьезной проблемой для метрических алгоритмов. Объекты часто оказываются на примерно одинаковом расстоянии друг от друга. Проклятие размерности может существенно мешать применению метрических алгоритмов.\n",
    "\n",
    "Способы борьбы:\n",
    "- понижение размерности пространства, спроецировать данные на подпространство меньшей размерности (как сделано в svm)\n",
    "- отбирать признаки на которых будет алгоритм убачаться, тем самым уменьшая размерность пространства\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
